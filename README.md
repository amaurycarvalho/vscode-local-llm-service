# vscode-local-llm-service
VSCode local LLM integration via Ollama running as a docker container
