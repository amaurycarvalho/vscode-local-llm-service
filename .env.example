# Ollama models
LLM_CODER_ULTRA_LIGHT=qwen2.5-coder:0.5b
LLM_CODER_LIGHT=deepseek-coder:1.3b
LLM_CODER_MODERATE=deepseek-coder:6.7b
LLM_CODER_FULL=deepseek-coder-v2:16b
LLM_CHAT_ULTRA_LIGHT=qwen3:0.6b
LLM_CHAT_LIGHT=deepseek-r1:1.5b
LLM_CHAT_MODERATE=deepseek-r1:7b
LLM_CHAT_FULL=deepseek-r1:14b
LLM_EMBED_ULTRA_LIGHT=qwen3-embedding:0.6b
LLM_EMBED_LIGHT=nomic-embed-text:v1.5

# Ollama setup
OLLAMA_HOST=http://ollama:11434
OLLAMA_DEFAULT_MODEL=${LLM_CHAT_ULTRA_LIGHT}
OLLAMA_LLM_CHAT=${LLM_CODER_ULTRA_LIGHT}
OLLAMA_LLM_AUTOCOMPLETE=${LLM_CODER_ULTRA_LIGHT}
OLLAMA_LLM_EMBED=${LLM_EMBED_ULTRA_LIGHT}

# LLM bridge setup
LLM_BRIDGE_SERVICE_NAME=llm-bridge
LLM_BRIDGE_PORT=3001
LLM_BRIDGE_API_KEY=write-here-your-own-bridge-api-key
LLM_BRIDGE_LOG_LEVEL=info
